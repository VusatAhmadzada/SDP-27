{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03782574",
   "metadata": {},
   "source": [
    "## Counting Words Appearances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cad1bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word frequency analysis completed. Results written to datasets/word_frequencies.txt.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def calculate_word_frequency(input_file, output_file):\n",
    "    \n",
    "    word_counter = Counter()\n",
    "\n",
    "    try:\n",
    "        with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "            for line in infile:\n",
    "                review = json.loads(line)  # Parse the JSON line\n",
    "                text = review.get('text', '')\n",
    "                # Normalize text: remove non-alphanumeric characters and convert to lowercase\n",
    "                words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "                word_counter.update(words)  # Update word frequency counter\n",
    "\n",
    "        # Write word frequencies to the output file\n",
    "        with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "            for word, count in word_counter.most_common():\n",
    "                outfile.write(f\"{word}: {count}\\n\")\n",
    "\n",
    "        print(f\"Word frequency analysis completed. Results written to {output_file}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# File paths\n",
    "input_file = \"datasets/filtered_hotel_reviews_cleaned_2.json\"  # Input JSON file with cleaned reviews\n",
    "output_file = \"datasets/word_frequencies.txt\"  # Output text file for word frequencies\n",
    "\n",
    "calculate_word_frequency(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdd8455",
   "metadata": {},
   "source": [
    "## Extracting Sensory Words from Hotel Reviews and Counting their Apppearances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36124a5",
   "metadata": {},
   "source": [
    "### 1. Exact Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec8a91cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sense_hotel_lexicons/exact_match\\sight_frequencies.txt\n",
      "Generated sense_hotel_lexicons/exact_match\\taste_frequencies.txt\n",
      "Generated sense_hotel_lexicons/exact_match\\touch_frequencies.txt\n",
      "Generated sense_hotel_lexicons/exact_match\\smell_frequencies.txt\n",
      "Generated sense_hotel_lexicons/exact_match\\sound_frequencies.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def load_word_frequencies(freq_file):\n",
    "    word_freq = {}\n",
    "    with open(freq_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(': ')\n",
    "            if len(parts) == 2:\n",
    "                word, freq = parts\n",
    "                word_freq[word] = int(freq)\n",
    "    return word_freq\n",
    "\n",
    "def process_sensory_file(sensory_file, word_freq):\n",
    "    sensory_word_counts = {}\n",
    "    with open(sensory_file, 'r', encoding='utf-8') as f:\n",
    "        for word in f:\n",
    "            word = word.strip().lower()\n",
    "            if word in word_freq:\n",
    "                sensory_word_counts[word] = word_freq[word]\n",
    "    return sensory_word_counts\n",
    "\n",
    "def write_output(sensory_file, sensory_word_counts, output_dir):\n",
    "    # Extract the base filename without directory path\n",
    "    base_filename = os.path.basename(sensory_file)\n",
    "    # Create output filename in the specified directory\n",
    "    output_file = os.path.join(output_dir, f\"{os.path.splitext(base_filename)[0]}_frequencies.txt\")\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for word, freq in sorted(sensory_word_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "            f.write(f\"{word}: {freq}\\n\")\n",
    "    print(f\"Generated {output_file}\")\n",
    "\n",
    "def main():\n",
    "    freq_file = \"datasets/word_frequencies.txt\"\n",
    "    sensory_files = [\"sense_vocab/sight.txt\", \"sense_vocab/taste.txt\", \"sense_vocab/touch.txt\", \"sense_vocab/smell.txt\", \"sense_vocab/sound.txt\"]\n",
    "    output_dir = \"sense_hotel_lexicons/exact_match\"\n",
    "    \n",
    "    word_freq = load_word_frequencies(freq_file)\n",
    "    \n",
    "    for sensory_file in sensory_files:\n",
    "        if os.path.exists(sensory_file):\n",
    "            sensory_word_counts = process_sensory_file(sensory_file, word_freq)\n",
    "            write_output(sensory_file, sensory_word_counts, output_dir)\n",
    "        else:\n",
    "            print(f\"File {sensory_file} not found!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92ff6da",
   "metadata": {},
   "source": [
    "### 2. Semantic Similarity with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "054ddc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading glove-wiki-gigaword-300 word embeddings...\n",
      "Processing 197 sensory words from sense_vocab/sight.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159131/159131 [03:08<00:00, 843.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sense_hotel_lexicons/semantic_match_glove\\sight_frequencies.txt and sense_hotel_lexicons/semantic_match_glove\\sight_matches.txt\n",
      "Processing 52 sensory words from sense_vocab/taste.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159131/159131 [00:26<00:00, 6044.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sense_hotel_lexicons/semantic_match_glove\\taste_frequencies.txt and sense_hotel_lexicons/semantic_match_glove\\taste_matches.txt\n",
      "Processing 122 sensory words from sense_vocab/touch.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159131/159131 [01:01<00:00, 2588.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sense_hotel_lexicons/semantic_match_glove\\touch_frequencies.txt and sense_hotel_lexicons/semantic_match_glove\\touch_matches.txt\n",
      "Processing 35 sensory words from sense_vocab/smell.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159131/159131 [00:17<00:00, 8962.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sense_hotel_lexicons/semantic_match_glove\\smell_frequencies.txt and sense_hotel_lexicons/semantic_match_glove\\smell_matches.txt\n",
      "Processing 198 sensory words from sense_vocab/sound.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159131/159131 [01:40<00:00, 1587.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sense_hotel_lexicons/semantic_match_glove\\sound_frequencies.txt and sense_hotel_lexicons/semantic_match_glove\\sound_matches.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "from tqdm import tqdm  # For progress bars\n",
    "\n",
    "def load_word_frequencies(freq_file):\n",
    "    \"\"\"Load word frequencies from the frequency file.\"\"\"\n",
    "    word_freq = {}\n",
    "    with open(freq_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(': ')\n",
    "            if len(parts) == 2:\n",
    "                word, freq = parts\n",
    "                word_freq[word] = int(freq)\n",
    "    return word_freq\n",
    "\n",
    "def load_word_embeddings(model_name=\"glove-wiki-gigaword-300\"):\n",
    "    \"\"\"Load pre-trained word embeddings.\"\"\"\n",
    "    print(f\"Loading {model_name} word embeddings...\")\n",
    "    return api.load(model_name)\n",
    "\n",
    "def process_sensory_file_semantic(sensory_file, word_freq, word_vectors, similarity_threshold=0.75):\n",
    "  \n",
    "    sensory_word_counts = {}\n",
    "    sensory_words = []\n",
    "    \n",
    "    # Load sensory words\n",
    "    with open(sensory_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            word = line.strip().lower()\n",
    "            if word in word_vectors:  # Make sure the sensory word is in our embeddings\n",
    "                sensory_words.append(word)\n",
    "    \n",
    "    print(f\"Processing {len(sensory_words)} sensory words from {sensory_file}\")\n",
    "    \n",
    "    # Create a mapping to track which frequency words matched with which sensory words\n",
    "    matches = {}\n",
    "    \n",
    "    # Check each word in the frequency dictionary\n",
    "    for freq_word in tqdm(word_freq.keys()):\n",
    "        if freq_word not in word_vectors:\n",
    "            continue\n",
    "            \n",
    "        # Check similarity with each sensory word\n",
    "        for sensory_word in sensory_words:\n",
    "            try:\n",
    "                similarity = word_vectors.similarity(freq_word, sensory_word)\n",
    "                \n",
    "                # If similarity is above threshold, consider it a match\n",
    "                if similarity >= similarity_threshold:\n",
    "                    if freq_word not in matches:\n",
    "                        matches[freq_word] = []\n",
    "                    matches[freq_word].append((sensory_word, similarity))\n",
    "                    \n",
    "                    # Count this word (if we have multiple matches, take the highest similarity one)\n",
    "                    if freq_word not in sensory_word_counts or similarity > max(s for _, s in matches[freq_word][:-1]):\n",
    "                        sensory_word_counts[freq_word] = word_freq[freq_word]\n",
    "            except KeyError:\n",
    "                continue  # Skip if either word is not in the vocabulary\n",
    "    \n",
    "    return sensory_word_counts, matches\n",
    "\n",
    "def write_output(sensory_file, sensory_word_counts, matches, output_dir):\n",
    "    \"\"\"Write output files with matched words and their origins.\"\"\"\n",
    "    # Extract the base filename without directory path\n",
    "    base_filename = os.path.basename(sensory_file)\n",
    "    base_name = os.path.splitext(base_filename)[0]\n",
    "    \n",
    "    # Create output filenames in the specified directory\n",
    "    output_file = os.path.join(output_dir, f\"{base_name}_frequencies.txt\")\n",
    "    matches_file = os.path.join(output_dir, f\"{base_name}_matches.txt\")\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Write frequencies\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for word, freq in sorted(sensory_word_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "            f.write(f\"{word}: {freq}\\n\")\n",
    "    \n",
    "    # Write matches information\n",
    "    with open(matches_file, 'w', encoding='utf-8') as f:\n",
    "        for freq_word, sensory_matches in sorted(matches.items()):\n",
    "            match_info = \", \".join([f\"{s_word} ({s:.2f})\" for s_word, s in sensory_matches])\n",
    "            f.write(f\"{freq_word} -> {match_info}\\n\")\n",
    "    \n",
    "    print(f\"Generated {output_file} and {matches_file}\")\n",
    "\n",
    "def main():\n",
    "    freq_file = \"datasets/word_frequencies.txt\"\n",
    "    sensory_files = [\"sense_vocab/sight.txt\", \"sense_vocab/taste.txt\", \"sense_vocab/touch.txt\", \"sense_vocab/smell.txt\", \"sense_vocab/sound.txt\"]\n",
    "    output_dir = \"sense_hotel_lexicons/semantic_match_glove\"\n",
    "    \n",
    "    # Load word frequencies\n",
    "    word_freq = load_word_frequencies(freq_file)\n",
    "    \n",
    "    # Load pre-trained word embeddings\n",
    "    word_vectors = load_word_embeddings()\n",
    "    \n",
    "    for sensory_file in sensory_files:\n",
    "        if os.path.exists(sensory_file):\n",
    "            sensory_word_counts, matches = process_sensory_file_semantic(sensory_file, word_freq, word_vectors)\n",
    "            write_output(sensory_file, sensory_word_counts, matches, output_dir)\n",
    "        else:\n",
    "            print(f\"File {sensory_file} not found!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9ffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load words from file 1\n",
    "with open('sense_vocab/sight.txt', 'r', encoding='utf-8') as f1:\n",
    "    file1_words = set(line.strip() for line in f1 if line.strip())\n",
    "\n",
    "# Load words from file 2 (ignoring counts)\n",
    "file2_words = set()\n",
    "with open('sense_hotel_lexicons/semantic_match_glove/sight_frequencies.txt', 'r', encoding='utf-8') as f2:\n",
    "    for line in f2:\n",
    "        if ':' in line:\n",
    "            word = line.split(':')[0].strip()\n",
    "            if word:\n",
    "                file2_words.add(word)\n",
    "\n",
    "# Difference\n",
    "unique_words = file2_words - file1_words\n",
    "\n",
    "# Save to a new file\n",
    "with open('sense_hotel_lexicons/semantic_match_glove/sigth_new_words.txt', 'w', encoding='utf-8') as out:\n",
    "    for word in sorted(unique_words):\n",
    "        out.write(word + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "234bda3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load words from file 1\n",
    "with open('sense_vocab/smell.txt', 'r', encoding='utf-8') as f1:\n",
    "    file1_words = set(line.strip() for line in f1 if line.strip())\n",
    "\n",
    "# Load words from file 2 (ignoring counts)\n",
    "file2_words = set()\n",
    "with open('sense_hotel_lexicons/semantic_match_glove/smell_frequencies.txt', 'r', encoding='utf-8') as f2:\n",
    "    for line in f2:\n",
    "        if ':' in line:\n",
    "            word = line.split(':')[0].strip()\n",
    "            if word:\n",
    "                file2_words.add(word)\n",
    "\n",
    "# Difference\n",
    "unique_words = file2_words - file1_words\n",
    "\n",
    "# Save to a new file\n",
    "with open('sense_hotel_lexicons/semantic_match_glove/smell_new_words.txt', 'w', encoding='utf-8') as out:\n",
    "    for word in sorted(unique_words):\n",
    "        out.write(word + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "021b8c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load words from file 1\n",
    "with open('sense_vocab/sound.txt', 'r', encoding='utf-8') as f1:\n",
    "    file1_words = set(line.strip() for line in f1 if line.strip())\n",
    "\n",
    "# Load words from file 2 (ignoring counts)\n",
    "file2_words = set()\n",
    "with open('sense_hotel_lexicons/semantic_match_glove/sound_frequencies.txt', 'r', encoding='utf-8') as f2:\n",
    "    for line in f2:\n",
    "        if ':' in line:\n",
    "            word = line.split(':')[0].strip()\n",
    "            if word:\n",
    "                file2_words.add(word)\n",
    "\n",
    "# Difference\n",
    "unique_words = file2_words - file1_words\n",
    "\n",
    "# Save to a new file\n",
    "with open('sense_hotel_lexicons/semantic_match_glove/sound_new_words.txt', 'w', encoding='utf-8') as out:\n",
    "    for word in sorted(unique_words):\n",
    "        out.write(word + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9859afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load words from file 1\n",
    "with open('sense_vocab/taste.txt', 'r', encoding='utf-8') as f1:\n",
    "    file1_words = set(line.strip() for line in f1 if line.strip())\n",
    "\n",
    "# Load words from file 2 (ignoring counts)\n",
    "file2_words = set()\n",
    "with open('sense_hotel_lexicons/semantic_match_glove/taste_frequencies.txt', 'r', encoding='utf-8') as f2:\n",
    "    for line in f2:\n",
    "        if ':' in line:\n",
    "            word = line.split(':')[0].strip()\n",
    "            if word:\n",
    "                file2_words.add(word)\n",
    "\n",
    "# Difference\n",
    "unique_words = file2_words - file1_words\n",
    "\n",
    "# Save to a new file\n",
    "with open('sense_hotel_lexicons/semantic_match_glove/taste_new_words.txt', 'w', encoding='utf-8') as out:\n",
    "    for word in sorted(unique_words):\n",
    "        out.write(word + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73e31167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load words from file 1\n",
    "with open('sense_vocab/touch.txt', 'r', encoding='utf-8') as f1:\n",
    "    file1_words = set(line.strip() for line in f1 if line.strip())\n",
    "\n",
    "# Load words from file 2 (ignoring counts)\n",
    "file2_words = set()\n",
    "with open('sense_hotel_lexicons/semantic_match_glove/touch_frequencies.txt', 'r', encoding='utf-8') as f2:\n",
    "    for line in f2:\n",
    "        if ':' in line:\n",
    "            word = line.split(':')[0].strip()\n",
    "            if word:\n",
    "                file2_words.add(word)\n",
    "\n",
    "# Difference\n",
    "unique_words = file2_words - file1_words\n",
    "\n",
    "# Save to a new file\n",
    "with open('sense_hotel_lexicons/semantic_match_glove/touch_new_words.txt', 'w', encoding='utf-8') as out:\n",
    "    for word in sorted(unique_words):\n",
    "        out.write(word + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07635180",
   "metadata": {},
   "source": [
    "### 3. Semantic Similarity with FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f21e091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fasttext-wiki-news-subwords-300 word embeddings...\n",
      "Warning: Sensory word 'looking glass' not found in FastText vocabulary\n",
      "Warning: Sensory word 'sharp sighted' not found in FastText vocabulary\n",
      "Warning: Sensory word 'stained stare' not found in FastText vocabulary\n",
      "Warning: Sensory word 'well groomed' not found in FastText vocabulary\n",
      "Processing 197 sensory words from sense_vocab/sight.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159131/159131 [01:57<00:00, 1352.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sense_hotel_lexicons/semantic_match_fasttext\\sight_frequencies.txt and sense_hotel_lexicons/semantic_match_fasttext\\sight_matches.txt\n",
      "Warning: Sensory word 'high-seasoned' not found in FastText vocabulary\n",
      "Processing 53 sensory words from sense_vocab/taste.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159131/159131 [00:45<00:00, 3532.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sense_hotel_lexicons/semantic_match_fasttext\\taste_frequencies.txt and sense_hotel_lexicons/semantic_match_fasttext\\taste_matches.txt\n",
      "Warning: Sensory word 'shuddery' not found in FastText vocabulary\n",
      "Processing 123 sensory words from sense_vocab/touch.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159131/159131 [01:02<00:00, 2563.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sense_hotel_lexicons/semantic_match_fasttext\\touch_frequencies.txt and sense_hotel_lexicons/semantic_match_fasttext\\touch_matches.txt\n",
      "Warning: Sensory word 'strong-scented' not found in FastText vocabulary\n",
      "Processing 37 sensory words from sense_vocab/smell.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159131/159131 [00:18<00:00, 8661.07it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sense_hotel_lexicons/semantic_match_fasttext\\smell_frequencies.txt and sense_hotel_lexicons/semantic_match_fasttext\\smell_matches.txt\n",
      "Warning: Sensory word '(meow)' not found in FastText vocabulary\n",
      "Warning: Sensory word 'sonic boom' not found in FastText vocabulary\n",
      "Processing 200 sensory words from sense_vocab/sound.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159131/159131 [02:20<00:00, 1128.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sense_hotel_lexicons/semantic_match_fasttext\\sound_frequencies.txt and sense_hotel_lexicons/semantic_match_fasttext\\sound_matches.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "from tqdm import tqdm  # For progress bars\n",
    "\n",
    "def load_word_frequencies(freq_file):\n",
    "    \"\"\"Load word frequencies from the frequency file.\"\"\"\n",
    "    word_freq = {}\n",
    "    with open(freq_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(': ')\n",
    "            if len(parts) == 2:\n",
    "                word, freq = parts\n",
    "                word_freq[word] = int(freq)\n",
    "    return word_freq\n",
    "\n",
    "def load_word_embeddings(model_name=\"fasttext-wiki-news-subwords-300\"):\n",
    "    \"\"\"Load pre-trained FastText word embeddings.\"\"\"\n",
    "    print(f\"Loading {model_name} word embeddings...\")\n",
    "    return api.load(model_name)\n",
    "\n",
    "def process_sensory_file_semantic(sensory_file, word_freq, word_vectors, similarity_threshold=0.75):\n",
    " \n",
    "    sensory_word_counts = {}\n",
    "    sensory_words = []\n",
    "    \n",
    "    # Load sensory words\n",
    "    with open(sensory_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            word = line.strip().lower()\n",
    "            if word in word_vectors:  # Make sure the sensory word is in our embeddings\n",
    "                sensory_words.append(word)\n",
    "            else:\n",
    "                print(f\"Warning: Sensory word '{word}' not found in FastText vocabulary\")\n",
    "    \n",
    "    print(f\"Processing {len(sensory_words)} sensory words from {sensory_file}\")\n",
    "    \n",
    "    # Create a mapping to track which frequency words matched with which sensory words\n",
    "    matches = {}\n",
    "    \n",
    "    # Check each word in the frequency dictionary\n",
    "    for freq_word in tqdm(word_freq.keys()):\n",
    "        if freq_word not in word_vectors:\n",
    "            continue\n",
    "            \n",
    "        # Check similarity with each sensory word\n",
    "        for sensory_word in sensory_words:\n",
    "            try:\n",
    "                similarity = word_vectors.similarity(freq_word, sensory_word)\n",
    "                \n",
    "                # If similarity is above threshold, consider it a match\n",
    "                if similarity >= similarity_threshold:\n",
    "                    if freq_word not in matches:\n",
    "                        matches[freq_word] = []\n",
    "                    matches[freq_word].append((sensory_word, similarity))\n",
    "                    \n",
    "                    # Count this word\n",
    "                    # If multiple sensory words match, we'll keep the highest similarity match\n",
    "                    if freq_word not in sensory_word_counts or similarity > max(s for _, s in matches[freq_word][:-1]):\n",
    "                        sensory_word_counts[freq_word] = word_freq[freq_word]\n",
    "            except KeyError:\n",
    "                continue  # Skip if either word is not in the vocabulary\n",
    "    \n",
    "    return sensory_word_counts, matches\n",
    "\n",
    "def write_output(sensory_file, sensory_word_counts, matches, output_dir):\n",
    "    \"\"\"Write output files with matched words and their origins.\"\"\"\n",
    "    # Extract the base filename without directory path\n",
    "    base_filename = os.path.basename(sensory_file)\n",
    "    base_name = os.path.splitext(base_filename)[0]\n",
    "    \n",
    "    # Create output filenames in the specified directory\n",
    "    output_file = os.path.join(output_dir, f\"{base_name}_frequencies.txt\")\n",
    "    matches_file = os.path.join(output_dir, f\"{base_name}_matches.txt\")\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Write frequencies\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for word, freq in sorted(sensory_word_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "            f.write(f\"{word}: {freq}\\n\")\n",
    "    \n",
    "    # Write matches information\n",
    "    with open(matches_file, 'w', encoding='utf-8') as f:\n",
    "        for freq_word, sensory_matches in sorted(matches.items()):\n",
    "            match_info = \", \".join([f\"{s_word} ({s:.2f})\" for s_word, s in sensory_matches])\n",
    "            f.write(f\"{freq_word} -> {match_info}\\n\")\n",
    "    \n",
    "    print(f\"Generated {output_file} and {matches_file}\")\n",
    "\n",
    "def main():\n",
    "    freq_file = \"datasets/word_frequencies.txt\"\n",
    "    sensory_files = [\"sense_vocab/sight.txt\", \"sense_vocab/taste.txt\", \"sense_vocab/touch.txt\", \"sense_vocab/smell.txt\", \"sense_vocab/sound.txt\"]\n",
    "    output_dir = \"sense_hotel_lexicons/semantic_match_fasttext\"\n",
    "    \n",
    "    # Load word frequencies\n",
    "    word_freq = load_word_frequencies(freq_file)\n",
    "    \n",
    "    # Load pre-trained word embeddings (FastText)\n",
    "    word_vectors = load_word_embeddings()\n",
    "    \n",
    "    for sensory_file in sensory_files:\n",
    "        if os.path.exists(sensory_file):\n",
    "            sensory_word_counts, matches = process_sensory_file_semantic(sensory_file, word_freq, word_vectors)\n",
    "            write_output(sensory_file, sensory_word_counts, matches, output_dir)\n",
    "        else:\n",
    "            print(f\"File {sensory_file} not found!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3c45920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load words from file 1\n",
    "with open('sense_vocab/touch.txt', 'r', encoding='utf-8') as f1:\n",
    "    file1_words = set(line.strip() for line in f1 if line.strip())\n",
    "\n",
    "# Load words from file 2 (ignoring counts)\n",
    "file2_words = set()\n",
    "with open('sense_hotel_lexicons/semantic_match_fasttext/sight_frequencies.txt', 'r', encoding='utf-8') as f2:\n",
    "    for line in f2:\n",
    "        if ':' in line:\n",
    "            word = line.split(':')[0].strip()\n",
    "            if word:\n",
    "                file2_words.add(word)\n",
    "\n",
    "# Difference\n",
    "unique_words = file2_words - file1_words\n",
    "\n",
    "# Save to a new file\n",
    "with open('sense_hotel_lexicons/semantic_match_fasttext/sight_new_words.txt', 'w', encoding='utf-8') as out:\n",
    "    for word in sorted(unique_words):\n",
    "        out.write(word + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90975ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load words from file 1\n",
    "with open('sense_vocab/smell.txt', 'r', encoding='utf-8') as f1:\n",
    "    file1_words = set(line.strip() for line in f1 if line.strip())\n",
    "\n",
    "# Load words from file 2 (ignoring counts)\n",
    "file2_words = set()\n",
    "with open('sense_hotel_lexicons/semantic_match_fasttext/smell_frequencies.txt', 'r', encoding='utf-8') as f2:\n",
    "    for line in f2:\n",
    "        if ':' in line:\n",
    "            word = line.split(':')[0].strip()\n",
    "            if word:\n",
    "                file2_words.add(word)\n",
    "\n",
    "# Difference\n",
    "unique_words = file2_words - file1_words\n",
    "\n",
    "# Save to a new file\n",
    "with open('sense_hotel_lexicons/semantic_match_fasttext/smell_new_words.txt', 'w', encoding='utf-8') as out:\n",
    "    for word in sorted(unique_words):\n",
    "        out.write(word + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "479e2395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load words from file 1\n",
    "with open('sense_vocab/sound.txt', 'r', encoding='utf-8') as f1:\n",
    "    file1_words = set(line.strip() for line in f1 if line.strip())\n",
    "\n",
    "# Load words from file 2 (ignoring counts)\n",
    "file2_words = set()\n",
    "with open('sense_hotel_lexicons/semantic_match_fasttext/sound_frequencies.txt', 'r', encoding='utf-8') as f2:\n",
    "    for line in f2:\n",
    "        if ':' in line:\n",
    "            word = line.split(':')[0].strip()\n",
    "            if word:\n",
    "                file2_words.add(word)\n",
    "\n",
    "# Difference\n",
    "unique_words = file2_words - file1_words\n",
    "\n",
    "# Save to a new file\n",
    "with open('sense_hotel_lexicons/semantic_match_fasttext/sound_new_words.txt', 'w', encoding='utf-8') as out:\n",
    "    for word in sorted(unique_words):\n",
    "        out.write(word + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dbf2c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load words from file 1\n",
    "with open('sense_vocab/taste.txt', 'r', encoding='utf-8') as f1:\n",
    "    file1_words = set(line.strip() for line in f1 if line.strip())\n",
    "\n",
    "# Load words from file 2 (ignoring counts)\n",
    "file2_words = set()\n",
    "with open('sense_hotel_lexicons/semantic_match_fasttext/taste_frequencies.txt', 'r', encoding='utf-8') as f2:\n",
    "    for line in f2:\n",
    "        if ':' in line:\n",
    "            word = line.split(':')[0].strip()\n",
    "            if word:\n",
    "                file2_words.add(word)\n",
    "\n",
    "# Difference\n",
    "unique_words = file2_words - file1_words\n",
    "\n",
    "# Save to a new file\n",
    "with open('sense_hotel_lexicons/semantic_match_fasttext/taste_new_words.txt', 'w', encoding='utf-8') as out:\n",
    "    for word in sorted(unique_words):\n",
    "        out.write(word + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa26a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load words from file 1\n",
    "with open('sense_vocab/touch.txt', 'r', encoding='utf-8') as f1:\n",
    "    file1_words = set(line.strip() for line in f1 if line.strip())\n",
    "\n",
    "# Load words from file 2 (ignoring counts)\n",
    "file2_words = set()\n",
    "with open('sense_hotel_lexicons/semantic_match_fasttext/touch_frequencies.txt', 'r', encoding='utf-8') as f2:\n",
    "    for line in f2:\n",
    "        if ':' in line:\n",
    "            word = line.split(':')[0].strip()\n",
    "            if word:\n",
    "                file2_words.add(word)\n",
    "\n",
    "# Difference\n",
    "unique_words = file2_words - file1_words\n",
    "\n",
    "# Save to a new file\n",
    "with open('sense_hotel_lexicons/semantic_match_fasttext/touch_new_words.txt', 'w', encoding='utf-8') as out:\n",
    "    for word in sorted(unique_words):\n",
    "        out.write(word + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e65f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
