{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00ee4f4d",
   "metadata": {},
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0753f34c",
   "metadata": {},
   "source": [
    "### 1. Extracting Hotel Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91629526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered businesses have been written to datasets/filtered_hotel_names.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def filter_businesses_with_hotels(input_file, output_file):\n",
    "\n",
    "    try:\n",
    "        # Open the input file and output file with UTF-8 encoding\n",
    "        with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "            # Iterate through each line (assuming each business is a JSON object in a new line)\n",
    "            for line in infile:\n",
    "                business = json.loads(line)  # Parse JSON string\n",
    "                categories = business.get(\"categories\", \"\")\n",
    "\n",
    "                # Check if 'Hotels' is in categories\n",
    "                if categories and \"Hotels\" in categories:\n",
    "                    outfile.write(json.dumps(business) + '\\n')  # Write JSON object as a single line\n",
    "\n",
    "            print(f\"Filtered businesses have been written to {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Input and output file paths\n",
    "input_file_path = \"datasets/yelp_academic_dataset_business.json\"  # Replace with the correct input file path\n",
    "output_file_path = \"datasets/filtered_hotel_names.json\"  # Replace with the desired output file path\n",
    "\n",
    "filter_businesses_with_hotels(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ab05f",
   "metadata": {},
   "source": [
    "### 2. Filtering Hotel reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cc502c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered reviews have been written to datasets/filtered_hotel_reviews.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def filter_reviews_by_business_ids(filtered_business_file, reviews_file, output_file):\n",
    " \n",
    "    try:\n",
    "        # Step 1: Load business_ids from filtered hotels\n",
    "        with open(filtered_business_file, 'r', encoding='utf-8') as f:\n",
    "            business_ids = {json.loads(line)['business_id'] for line in f}\n",
    "\n",
    "        # Step 2: Filter reviews by matching business_ids\n",
    "        with open(reviews_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "            for line in infile:\n",
    "                review = json.loads(line)  # Parse review JSON\n",
    "                if review['business_id'] in business_ids:  # Check if business_id matches\n",
    "                    outfile.write(json.dumps(review) + '\\n')  # Write review to output file\n",
    "\n",
    "        print(f\"Filtered reviews have been written to {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# File paths\n",
    "filtered_business_file = \"datasets/filtered_hotel_names.json\"  # File with filtered hotels\n",
    "reviews_file = \"datasets/yelp_academic_dataset_review.json\"  # File containing reviews\n",
    "output_file = \"datasets/filtered_hotel_reviews.json\"  # Output file for filtered reviews\n",
    "\n",
    "filter_reviews_by_business_ids(filtered_business_file, reviews_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e230235",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81de2f31",
   "metadata": {},
   "source": [
    "### 1. Removing Non-English Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8819059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10000 reviews so far. Filtered 9984 English reviews.\n",
      "Processed 20000 reviews so far. Filtered 19966 English reviews.\n",
      "Processed 30000 reviews so far. Filtered 29957 English reviews.\n",
      "Processed 40000 reviews so far. Filtered 39947 English reviews.\n",
      "Processed 50000 reviews so far. Filtered 49930 English reviews.\n",
      "Processed 60000 reviews so far. Filtered 59921 English reviews.\n",
      "Processed 70000 reviews so far. Filtered 69914 English reviews.\n",
      "Processed 80000 reviews so far. Filtered 79900 English reviews.\n",
      "Processed 90000 reviews so far. Filtered 89885 English reviews.\n",
      "Processed 100000 reviews so far. Filtered 99877 English reviews.\n",
      "Processed 110000 reviews so far. Filtered 109853 English reviews.\n",
      "Processed 120000 reviews so far. Filtered 119837 English reviews.\n",
      "Processed 130000 reviews so far. Filtered 129824 English reviews.\n",
      "Processed 140000 reviews so far. Filtered 139807 English reviews.\n",
      "Skipping review 145345: No features in text.\n",
      "Processed 150000 reviews so far. Filtered 149791 English reviews.\n",
      "Processed 160000 reviews so far. Filtered 159780 English reviews.\n",
      "Processed 170000 reviews so far. Filtered 169751 English reviews.\n",
      "Processed 180000 reviews so far. Filtered 179739 English reviews.\n",
      "Processed 190000 reviews so far. Filtered 189726 English reviews.\n",
      "Processed 200000 reviews so far. Filtered 199714 English reviews.\n",
      "Processed 210000 reviews so far. Filtered 209693 English reviews.\n",
      "Processed 220000 reviews so far. Filtered 219680 English reviews.\n",
      "Processed 230000 reviews so far. Filtered 229669 English reviews.\n",
      "Processed 240000 reviews so far. Filtered 239650 English reviews.\n",
      "Processed 250000 reviews so far. Filtered 249637 English reviews.\n",
      "Processed 260000 reviews so far. Filtered 259632 English reviews.\n",
      "Processed 270000 reviews so far. Filtered 269621 English reviews.\n",
      "Processed 280000 reviews so far. Filtered 279603 English reviews.\n",
      "Processed 290000 reviews so far. Filtered 289593 English reviews.\n",
      "Processed 300000 reviews so far. Filtered 299584 English reviews.\n",
      "Skipping review 300691: No features in text.\n",
      "Processed 310000 reviews so far. Filtered 309565 English reviews.\n",
      "Processed 320000 reviews so far. Filtered 319547 English reviews.\n",
      "Completed. Filtered 329199 English reviews out of 329658 total reviews.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langdetect import detect, DetectorFactory\n",
    "\n",
    "# Ensure consistent results from the langdetect library\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "def remove_non_english_reviews(input_file, output_file):\n",
    "\n",
    "    try:\n",
    "        with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "            count = 0\n",
    "            filtered_count = 0\n",
    "\n",
    "            for line in infile:\n",
    "                count += 1\n",
    "                review = json.loads(line)\n",
    "                text = review.get('text', '')\n",
    "\n",
    "                try:\n",
    "                    # Detect language and keep only English reviews\n",
    "                    if detect(text) == 'en':\n",
    "                        json.dump(review, outfile)\n",
    "                        outfile.write('\\n')\n",
    "                        filtered_count += 1\n",
    "                except Exception as e:\n",
    "                    # Skip reviews where language detection fails\n",
    "                    print(f\"Skipping review {count}: {e}\")\n",
    "\n",
    "                if count % 10000 == 0:  # Progress update every 10k reviews\n",
    "                    print(f\"Processed {count} reviews so far. Filtered {filtered_count} English reviews.\")\n",
    "\n",
    "        print(f\"Completed. Filtered {filtered_count} English reviews out of {count} total reviews.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# File paths\n",
    "input_file = \"datasets/filtered_hotel_reviews.json\"  # Input JSON file with reviews\n",
    "output_file = \"datasets/filtered_hotel_reviews_cleaned.json\"  # Output JSON file with only English reviews\n",
    "\n",
    "remove_non_english_reviews(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c84ee",
   "metadata": {},
   "source": [
    "### 2. Cleaning Further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c1827f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned reviews saved to datasets/filtered_hotel_reviews_cleaned_2.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data (run once)\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "def clean_reviews(input_file, output_file):\n",
    "    try:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "        # Read and clean reviews, then write them back\n",
    "        with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "            for line in infile:\n",
    "                review_obj = json.loads(line)\n",
    "                # Clean the review text\n",
    "                review_obj['text'] = clean_text(review_obj['text'], stop_words)\n",
    "                # Write the modified review object to output file\n",
    "                outfile.write(json.dumps(review_obj) + '\\n')\n",
    "        \n",
    "        print(f\"Cleaned reviews saved to {output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def clean_text(text, stop_words):\n",
    "    \"\"\"Clean text by removing URLs, HTML, special characters, and stop words.\"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove email addresses\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s.,!?]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Remove stop words\n",
    "    words = text.split()\n",
    "    text = ' '.join([word for word in words if word not in stop_words])\n",
    "    \n",
    "    return text\n",
    "\n",
    "input_file = \"datasets/filtered_hotel_reviews_cleaned.json\"\n",
    "output_file = \"datasets/filtered_hotel_reviews_cleaned_2.json\"\n",
    "    \n",
    "clean_reviews(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec679f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
